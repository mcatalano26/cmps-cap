{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from compress_pickle import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pd.read_csv('files/compiled_comments_3_14_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_train_test_split(df, feature_list, target_name, test_size):\n",
    "    X = df[feature_list]\n",
    "    X = X.to_numpy()\n",
    "    y = df[target_name]\n",
    "    y = y.to_numpy()\n",
    "    rand_state = random.randint(0, 1000)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=rand_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def determine_accuracy(y_test, y_val):\n",
    "    percent_arr = (y_test == y_val)\n",
    "    count = np.count_nonzero(percent_arr)\n",
    "    percentage = (count/(len(percent_arr)))*100\n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Random Forest Classifier\n",
    "def random_forest_class_func(df, feature_list, target_name, test_size, estimators):\n",
    "    #set up training and testing split\n",
    "    X_train, X_test, y_train, y_test = set_up_train_test_split(df, feature_list, target_name, test_size)\n",
    "    \n",
    "    #fit ridge classifier to x and y training set\n",
    "    clf = RandomForestClassifier(n_estimators = estimators).fit(X_train, y_train)\n",
    "    \n",
    "    #pickle the model\n",
    "    fname1 = \"compressed_model.pkl\"\n",
    "    #dump(clf, fname1)\n",
    "    dump(clf, fname1, compression=\"lzma\", set_default_extension=False)\n",
    "    \n",
    "    importances = clf.feature_importances_\n",
    "    \n",
    "    #Predict with ridge classifier on x and y testing set\n",
    "    y_val = clf.predict(X_test)\n",
    "    \n",
    "    #report the correct percentage of predictions\n",
    "    percentage = determine_accuracy(y_test, y_val)\n",
    "    \n",
    "    #Send data to csv to keep track of data\n",
    "    data = [[feature_list, test_size, percentage, estimators]]\n",
    "    return_df = pd.DataFrame(data, columns = ['features', 'test size', 'percent correct', 'n_estimators'])\n",
    "    return_df.to_csv('files/ML_Results/RandomForestClassifier_Results.csv', mode='a', header=False, index=False)\n",
    "    \n",
    "    print('Percentage correct: ' + str(percentage) + '\\n')\n",
    "    plt.barh(feature_list, importances)\n",
    "    plt.title('Feature importance of random forest classifier with test_size=' + str(test_size))\n",
    "    \n",
    "    return y_val\n",
    "\n",
    "features = ['NER_count', 'NER_match', 'tfidf', 'WordScore', 'WholeScore', 'contains_url', 'adjWordScore', 'no_url_WordScore', 'no_url_WholeScore', 'WordScoreNoStop', 'WholeScoreNoStop', 'no_url_or_stops_WholeScore', 'no_url_or_stops_WordScore']\n",
    "test = random_forest_class_func(comments_df, features, 'action', 0.1, 1000)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'compressed_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c5916dd29293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcompress_pickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compressed_model.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lzma\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_default_extension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Then do whatever you need to with the model variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/compress_pickle/compress_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compression, pickler_method, pickler_kwargs, mode, set_default_extension, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mset_default_extension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_default_extension\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpickler_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/compress_pickle/utils.py\u001b[0m in \u001b[0;36minstantiate_compresser\u001b[0;34m(compression, path, mode, set_default_extension, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_compression_read_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     compresser = compresser_class(\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0m_path\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     )\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompresser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/compress_pickle/compressers/lzma.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH_TYPES\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIOBase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unhandled path type {type(path)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlzma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/lzma.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, format, check, preset, filters, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mlz_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     binary_file = LZMAFile(filename, lz_mode, format=format, check=check,\n\u001b[0;32m--> 302\u001b[0;31m                            preset=preset, filters=filters)\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"t\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/lzma.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, format, check, preset, filters)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closefp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'compressed_model.pkl'"
     ]
    }
   ],
   "source": [
    "#To load the model, run the following\n",
    "import pickle\n",
    "from compress_pickle import dump, load\n",
    "model = load(\"compressed_model.pkl\", compression=\"lzma\", set_default_extension=False)\n",
    "\n",
    "#Then do whatever you need to with the model variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comments_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-24e947c4c82c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Double checking that the model variable still works. It does\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'NER_count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NER_match'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tfidf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'WordScore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'WholeScore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'contains_url'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'adjWordScore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'no_url_WordScore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'no_url_WholeScore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'WordScoreNoStop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'WholeScoreNoStop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'no_url_or_stops_WholeScore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'no_url_or_stops_WordScore'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_up_train_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomments_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'action'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'comments_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Double checking that the model variable still works. It does\n",
    "features = ['NER_count', 'NER_match', 'tfidf', 'WordScore', 'WholeScore', 'contains_url', 'adjWordScore', 'no_url_WordScore', 'no_url_WholeScore', 'WordScoreNoStop', 'WholeScoreNoStop', 'no_url_or_stops_WholeScore', 'no_url_or_stops_WordScore']\n",
    "X_train, X_test, y_train, y_test = set_up_train_test_split(comments_df, features, 'action', 0.1)\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
